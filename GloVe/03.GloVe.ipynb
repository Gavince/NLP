{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe-基于全局共现词频信息的词嵌入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend you take a look at these material first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture3.pdf\n",
    "* https://nlp.stanford.edu/pubs/glove.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "def flatten(l): return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "gpus = [0]\n",
    "torch.cuda.set_device(gpus[0])\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "\n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(\n",
    "        w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))\n",
    "\n",
    "\n",
    "def prepare_word(word, word2index):\n",
    "    return Variable(LongTensor([word2index[word]]) if word2index.get(word) is not None else LongTensor([word2index[\"<UNK>\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'moby', 'dick', 'by', 'herman', 'melville', '1851', ']']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(nltk.corpus.gutenberg.sents('melville-moby_dick.txt'))[:500]\n",
    "corpus = [[word.lower() for word in sent] for sent in corpus]\n",
    "corpus[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(flatten(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "\n",
    "index2word = {v: k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5\n",
    "# 窗口大小为10\n",
    "windows = flatten([list(nltk.ngrams(['<DUMMY>'] * WINDOW_SIZE + c +\n",
    "                                    ['<DUMMY>'] * WINDOW_SIZE, WINDOW_SIZE * 2 + 1)) for c in corpus])\n",
    "\n",
    "window_data = []\n",
    "\n",
    "for window in windows:\n",
    "    for i in range(WINDOW_SIZE * 2 + 1):\n",
    "        if i == WINDOW_SIZE or window[i] == '<DUMMY>':\n",
    "            continue\n",
    "        # 中心词 + 上下问词\n",
    "        window_data.append((window[WINDOW_SIZE], window[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Weighting Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/03.glove-weighting-function.png\">\n",
    "<center>borrowed image from https://nlp.stanford.edu/pubs/glove.pdf</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting(w_i, w_j):\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i, w_j)]\n",
    "    except:\n",
    "        x_ij = 1\n",
    "\n",
    "    x_max = 100  # 100 # fixed in paper\n",
    "    alpha = 0.75\n",
    "\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha\n",
    "    else:\n",
    "        result = 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Co-occurence Matrix X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of model complexity, It is important to determine whether a tighter bound can be placed on the number of nonzero elements of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_i = Counter(flatten(corpus))  # X_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ik_window_5 = Counter(window_data)  # Co-occurece in window size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ik = {}\n",
    "weighting_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bigram in combinations_with_replacement(vocab, 2):\n",
    "    if X_ik_window_5.get(bigram) is not None:  # nonzero elements\n",
    "        co_occer = X_ik_window_5[bigram]\n",
    "        # log(Xik) -> log(Xik+1) to prevent divergence\n",
    "        # i是ｋ的共现，则k也是i的共现\n",
    "        X_ik[bigram] = co_occer + 1\n",
    "        X_ik[(bigram[1], bigram[0])] = co_occer+1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    weighting_dic[bigram] = weighting(bigram[0], bigram[1])\n",
    "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('judgmatically', ',')\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test = random.choice(window_data)\n",
    "print(test)\n",
    "try:\n",
    "    print(X_ik[(test[0], test[1])] == X_ik[(test[1], test[0])])\n",
    "except:\n",
    "    1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[536]], device='cuda:0'), tensor([[916]], device='cuda:0'), tensor([[0.6931]], device='cuda:0'), tensor([[0.0532]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "u_p = []  # center vec\n",
    "v_p = []  # context vec\n",
    "co_p = []  # log(x_ij)\n",
    "weight_p = []  # f(x_ij)\n",
    "\n",
    "for pair in window_data:\n",
    "    u_p.append(prepare_word(pair[0], word2index).view(1, -1))\n",
    "    v_p.append(prepare_word(pair[1], word2index).view(1, -1))\n",
    "\n",
    "    try:\n",
    "        cooc = X_ik[pair]\n",
    "    except:\n",
    "        cooc = 1\n",
    "\n",
    "    co_p.append(torch.log(Variable(FloatTensor([cooc]))).view(1, -1))\n",
    "    weight_p.append(Variable(FloatTensor([weighting_dic[pair]])).view(1, -1))\n",
    "\n",
    "train_data = list(zip(u_p, v_p, co_p, weight_p))\n",
    "del u_p\n",
    "del v_p\n",
    "del co_p\n",
    "del weight_p\n",
    "# tuple (center vec i, context vec j log(x_ij), weight f(w_ij))\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "- 对Embed-V和Embed-U做加和，以得到最终的Embedding向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, projection_dim):\n",
    "        super(GloVe, self).__init__()\n",
    "        self.embedding_v = nn.Embedding(\n",
    "            vocab_size, projection_dim)  # center embedding\n",
    "        self.embedding_u = nn.Embedding(\n",
    "            vocab_size, projection_dim)  # out embedding\n",
    "\n",
    "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
    "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
    "\n",
    "        initrange = (2.0 / (vocab_size + projection_dim))**0.5  # Xavier init\n",
    "        self.embedding_v.weight.data.uniform_(-initrange, initrange)  # init\n",
    "        self.embedding_u.weight.data.uniform_(-initrange, initrange)  # init\n",
    "        self.v_bias.weight.data.uniform_(-initrange, initrange)  # init\n",
    "        self.u_bias.weight.data.uniform_(-initrange, initrange)  # init\n",
    "\n",
    "    def forward(self, center_words, target_words, coocs, weights):\n",
    "        center_embeds = self.embedding_v(center_words)  # B x 1 x D\n",
    "        target_embeds = self.embedding_u(target_words)  # B x 1 x D\n",
    "\n",
    "        center_bias = self.v_bias(center_words).squeeze(1)\n",
    "        target_bias = self.u_bias(target_words).squeeze(1)\n",
    "\n",
    "        inner_product = target_embeds.bmm(\n",
    "            center_embeds.transpose(1, 2)).squeeze(2)  # Bx1\n",
    "\n",
    "        loss = weights*torch.pow(inner_product +\n",
    "                                 center_bias + target_bias - coocs, 2)\n",
    "\n",
    "        return torch.sum(loss)\n",
    "\n",
    "    def prediction(self, inputs):\n",
    "        \"\"\"Embedding做加和\"\"\"\n",
    "\n",
    "        v_embeds = self.embedding_v(inputs)  # B x 1 x D\n",
    "        u_embeds = self.embedding_u(inputs)  # B x 1 x D\n",
    "\n",
    "        return v_embeds+u_embeds  # final embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GloVe(\n",
       "  (embedding_v): Embedding(2607, 50)\n",
       "  (embedding_u): Embedding(2607, 50)\n",
       "  (v_bias): Embedding(2607, 1)\n",
       "  (u_bias): Embedding(2607, 1)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "model = GloVe(len(word2index), EMBEDDING_SIZE)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, mean_loss : 216.76\n",
      "Epoch : 10, mean_loss : 2.69\n",
      "Epoch : 20, mean_loss : 0.56\n",
      "Epoch : 30, mean_loss : 0.13\n",
      "Epoch : 40, mean_loss : 0.04\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
    "\n",
    "        inputs, targets, coocs, weights = zip(*batch)\n",
    "\n",
    "        inputs = torch.cat(inputs)  # B x 1\n",
    "        targets = torch.cat(targets)  # B x 1\n",
    "        coocs = torch.cat(coocs)\n",
    "        weights = torch.cat(weights)\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss = model(inputs, targets, coocs, weights)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.data.tolist())\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch : %d, mean_loss : %.02f\" % (epoch, np.mean(losses)))\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(target, vocab):\n",
    "    if USE_CUDA:\n",
    "        target_V = model.prediction(prepare_word(target, word2index))\n",
    "    else:\n",
    "        target_V = model.prediction(prepare_word(target, word2index))\n",
    "    similarities = []\n",
    "    for i in range(len(vocab)):\n",
    "        if vocab[i] == target:\n",
    "            continue\n",
    "\n",
    "        if USE_CUDA:\n",
    "            vector = model.prediction(prepare_word(list(vocab)[i], word2index))\n",
    "        else:\n",
    "            vector = model.prediction(prepare_word(list(vocab)[i], word2index))\n",
    "\n",
    "        cosine_sim = F.cosine_similarity(target_V, vector).data.tolist()[0]\n",
    "        similarities.append([vocab[i], cosine_sim])\n",
    "\n",
    "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absent'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = random.choice(list(vocab))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['minded', 0.9209498763084412],\n",
       " ['unite', 0.7793592214584351],\n",
       " ['quietest', 0.7789486050605774],\n",
       " ['building', 0.7681793570518494],\n",
       " ['barques', 0.7526453137397766],\n",
       " ['invitingly', 0.7422810196876526],\n",
       " ['possible', 0.7392736077308655],\n",
       " ['vessel', 0.738730251789093],\n",
       " ['schooners', 0.7365476489067078],\n",
       " ['covered', 0.7356072068214417]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity(test, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pytorch-glove](https://github.com/liulu1Q84/pytorch-glove/blob/master/glove.py)  \n",
    "[词嵌入-GloVe-基于全局共现词频信息的词嵌入](https://zhuanlan.zhihu.com/p/485447934)  \n",
    "[理解GloVe模型（Global vectors for word representation）](https://blog.csdn.net/coderTC/article/details/73864097)  \n",
    "[NLP.TM | GloVe模型的原理和实现](https://zhuanlan.zhihu.com/p/60392680)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
