{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNLM 模型\n",
    "**Definition**: A n-gram is a chunk of n consecutive words.  \n",
    "• **uni**grams: “the”, “students”, “opened”, ”their”  \n",
    "• **bi**grams: “the students”, “students opened”, “opened their”  \n",
    "• **tri**grams: “the students opened”, “students opened their”  \n",
    "• 4-grams: “the students opened their  \n",
    "**Idea**: Collect statistics about how frequent different n-grams are and use these to\n",
    "predict next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据我们使用的是莎士比亚的14行诗\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "                And dig deep trenches in thy beauty's field,\n",
    "                Thy youth's proud livery so gazed on now,\n",
    "                Will be a totter'd weed of small worth held:\n",
    "                Then being asked, where all thy beauty lies,\n",
    "                Where all the treasure of thy lusty days;\n",
    "                To say, within thine own deep sunken eyes,\n",
    "                Were an all-eating shame, and thriftless praise.\n",
    "                How much more praise deserv'd thy beauty's use,\n",
    "                If thou couldst answer 'This fair child of mine\n",
    "                Shall sum my count, and make my old excuse,'\n",
    "                Proving his beauty by succession thine!\n",
    "                This were to be new made when thou art old,\n",
    "                And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "\n",
    "\n",
    "# 将单词序列转化为数据元组列表，\n",
    "# 其中的每个元组格式为([ word_i-2, word_i-1 ], target word)\n",
    "trigrams = [([test_sentence[i], test_sentence[i+1]], test_sentence[i+2])\n",
    "            for i in range(len(test_sentence) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['When', 'forty'], 'winters')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印出前3条数据，注意观察数据的结构\n",
    "trigrams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给14行诗建立单词表\n",
    "# set 即去除重复的词\n",
    "vocab = set(test_sentence)\n",
    "# 建立词典，它比单词表多了每个词的索引\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "模型架构：  \n",
    "1. 模型一共三层，第一层是映射层，将n个单词映射为对应word embeddings的拼接，其实这一层就是MLP的输入层；第二层是隐藏层，激活函数用tanh；第三层是输出层，因为是语言模型，需要根据前n个单词预测下一个单词，所以是一个多分类器，用softmax。整个模型最大的计算量集中在最后一层上，因为一般来说词汇表都很大，需要计算每个单词的条件概率，是整个模型的计算瓶颈。\n",
    "\n",
    "2. 这里，需要注意的是需要提前初始化一个word embedding矩阵，每一行表示一个单词的向量。词向量也是训练参数，在每次训练中进行更新。这里可以看出词向量是语言模型的一个附属品，因为语言模型本身的工作是为了估计给定的一句话有多像人类的话，但从后来的研究发现，语言模型成了一个非常好的工具。\n",
    "\n",
    "3. softmax是一个非常低效的处理方式，需要先计算每个单词的概率，并且还要计算指数，指数在计算机中都是用级数来近似的，计算复杂度很高，最后再做归一化处理。此后很多研究都针对这个问题进行了优化，比如层级softmax，比如softmax tree。\n",
    "![](./imgs/ngram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        # 通过 log_softmax 方法将结果映射为概率的log\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "loss_function = nn.NLLLoss()\n",
    "# 单词表的大小、嵌入维度、上下文长度\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGramLanguageModeler(\n",
       "  (embeddings): Embedding(97, 10)\n",
       "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=97, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<01:06, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 4.66568660736084 of 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 104/1000 [00:06<00:56, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 3.462538719177246 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 204/1000 [00:12<00:47, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 1.0630207061767578 of 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 304/1000 [00:18<00:42, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 0.23098227381706238 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 402/1000 [00:24<00:40, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 0.10503446310758591 of 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 504/1000 [00:31<00:30, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 0.06432755291461945 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 604/1000 [00:37<00:23, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 0.04525027051568031 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 702/1000 [00:44<00:20, 14.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 0.034482017159461975 of 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 802/1000 [00:51<00:16, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 0.02763105183839798 of 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [00:58<00:07, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss 0.022926034405827522 of 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:04<00:00, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1000)):\n",
    "\n",
    "    total_loss = 0\n",
    "    # 循环context上下文，比如：['When', 'forty']\n",
    "    # target，比如：winters\n",
    "    for context, target in trigrams:\n",
    "        # 将context如“['When', 'forty']”\n",
    "        # 转化为索引，如[68, 15]\n",
    "        context_idxs = list(map(lambda w: word_to_ix[w], context))\n",
    "        context_var = autograd.Variable(torch.LongTensor(context_idxs))\n",
    "        # 步骤2：清空梯度值，防止上次的梯度累计\n",
    "        model.zero_grad()\n",
    "        # 步骤3：运行网络的正向传播，获得 log 概率\n",
    "        log_probs = model(context_var)\n",
    "        loss = loss_function(log_probs, autograd.Variable(\n",
    "            torch.LongTensor([word_to_ix[target]])))\n",
    "        # 步骤5：进行反向传播并更新梯度\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"The loss {} of {}\".format(loss.data, epoch))\n",
    "\n",
    "    losses.append(total_loss)\n",
    "\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析\n",
    "模型的优缺点:  \n",
    "![](./imgs/weak.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "[原文地址](https://link.zhihu.com/?target=https%3A//www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)  \n",
    "[【论文阅读】A Neural Probabilistic Language Mode](https://blog.csdn.net/u014568072/article/details/78557837?spm=1001.2101.3001.6650.10&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7ERate-10.topblog&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7ERate-10.topblog&utm_relevant_index=11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
